% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/descente_gradient.R
\name{descente_gradient}
\alias{descente_gradient}
\title{Gradient Descent Function for Logistic Regression}
\usage{
descente_gradient(
  X,
  y,
  theta,
  nb_iters = 1000,
  alpha = 0.01,
  penalty = NULL,
  lambda = 0,
  l1_ratio = 0
)
}
\arguments{
\item{X}{: feature matrix}

\item{y}{: label vector}

\item{theta}{: parameter vector}

\item{nb_iters}{: number of iterations to perform}

\item{alpha}{: learning rate}

\item{penalty}{: type of regularization: l1=lasso, l2=ridge, elasticnet}

\item{lambda}{: regularization parameter}

\item{l1_ratio}{: l1 regularization ratio}
}
\value{
list of optimized parameters
}
\description{
applies the gradient descent to optimize the \code{theta} parameters
with the possibility to add L1, L2, or ElasticNet regularization
}
